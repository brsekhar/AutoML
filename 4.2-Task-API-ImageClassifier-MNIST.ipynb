{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ImageClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aX1dRHHVUUs",
        "outputId": "2a40074d-070b-40ce-dc0f-51406b12974f"
      },
      "source": [
        "pip install autokeras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting autokeras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/12/cf698586ccc8245f08d1843dcafb65b064a2e9e2923b889dc58e1019f099/autokeras-1.0.12-py3-none-any.whl (164kB)\n",
            "\r\u001b[K     |██                              | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 31.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 33.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 35.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 38.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81kB 24.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92kB 22.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102kB 23.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112kB 23.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 122kB 23.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 133kB 23.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 143kB 23.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 153kB 23.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 23.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 23.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from autokeras) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from autokeras) (1.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from autokeras) (20.8)\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from autokeras) (2.4.0)\n",
            "Collecting keras-tuner>=1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->autokeras) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->autokeras) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->autokeras) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->autokeras) (2.4.7)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (3.7.4.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.10.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (0.36.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.2->autokeras) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.3.0->autokeras) (51.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp36-none-any.whl size=78939 sha256=2f90b2ab84be72a51551e27f140ee0ff75b6a48855cf42714547f2877b9f09ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=f6f70b7457350b313cbd123258c5c5d5461119192d6a5a912309e217e26c05a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner, autokeras\n",
            "Successfully installed autokeras-1.0.12 colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY8mFN25TMTQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import autokeras as ak"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwvxeCIeTMTU"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_visible_devices(gpus[-1], 'GPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HwXoew2D2vT"
      },
      "source": [
        "## A Simple Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D7scqBWkg5t"
      },
      "source": [
        "### Load MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YACSvJ81h_Ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10256c61-2c7b-4896-c7d2-d8bd7a869d98"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print('Training image shape:', x_train.shape) # (60000, 28, 28)\n",
        "print('Training label shape:', y_train.shape) # (60000,)\n",
        "print('First five training labels:', y_train[:5]) # array([5 0 4 1 9], dtype=uint8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Training image shape: (60000, 28, 28)\n",
            "Training label shape: (60000,)\n",
            "First five training labels: [5 0 4 1 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5xlStkakqJn"
      },
      "source": [
        "### Run the ImageClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfnaDrkPiTTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab33d940-fb43-42c5-afde-f0fd43e8f36a"
      },
      "source": [
        "# Initialize the image classifier.\n",
        "clf = ak.ImageClassifier(max_trials=2) # It tries two different models.\n",
        "\n",
        "# Feed the image classifier with training data \n",
        "# 20% of the data is used as validation data by default for tuning\n",
        "# the process may run for a bit long time, please try to use GPU\n",
        "clf.fit(x_train, y_train, epochs=3) # each model is trained for three epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 2 Complete [00h 26m 02s]\n",
            "val_loss: 0.4253802001476288\n",
            "\n",
            "Best val_loss So Far: 0.04771251976490021\n",
            "Total elapsed time: 00h 26m 32s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2961 - accuracy: 0.9101\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0790 - accuracy: 0.9763\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0596 - accuracy: 0.9815\n",
            "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARsP9EliTMTa"
      },
      "source": [
        "### Get the summarized results during the tuning process (return the best 10 models if existed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u1ScNTnTMTb",
        "outputId": "819bb0f6-c500-4b07-ed83-da0ba013bdb4"
      },
      "source": [
        "clf.tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./image_classifier\n",
            "Showing 10 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "image_block_1/block_type: vanilla\n",
            "image_block_1/normalize: True\n",
            "image_block_1/augment: False\n",
            "image_block_1/conv_block_1/kernel_size: 3\n",
            "image_block_1/conv_block_1/num_blocks: 1\n",
            "image_block_1/conv_block_1/num_layers: 2\n",
            "image_block_1/conv_block_1/max_pooling: True\n",
            "image_block_1/conv_block_1/separable: False\n",
            "image_block_1/conv_block_1/dropout: 0.25\n",
            "image_block_1/conv_block_1/filters_0_0: 32\n",
            "image_block_1/conv_block_1/filters_0_1: 64\n",
            "classification_head_1/spatial_reduction_1/reduction_type: flatten\n",
            "classification_head_1/dropout: 0.5\n",
            "optimizer: adam\n",
            "learning_rate: 0.001\n",
            "Score: 0.04718967527151108\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "image_block_1/block_type: resnet\n",
            "image_block_1/normalize: True\n",
            "image_block_1/augment: True\n",
            "image_block_1/image_augmentation_1/horizontal_flip: True\n",
            "image_block_1/image_augmentation_1/vertical_flip: True\n",
            "image_block_1/image_augmentation_1/contrast_factor: 0.0\n",
            "image_block_1/image_augmentation_1/rotation_factor: 0.0\n",
            "image_block_1/image_augmentation_1/translation_factor: 0.1\n",
            "image_block_1/image_augmentation_1/zoom_factor: 0.0\n",
            "image_block_1/res_net_block_1/pretrained: False\n",
            "image_block_1/res_net_block_1/version: resnet50\n",
            "image_block_1/res_net_block_1/imagenet_size: True\n",
            "classification_head_1/spatial_reduction_1/reduction_type: global_avg\n",
            "classification_head_1/dropout: 0\n",
            "optimizer: adam\n",
            "learning_rate: 0.001\n",
            "Score: 0.30901777744293213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQCbEqK8TMTd"
      },
      "source": [
        "### Retrieve best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsQ2Ips4TMTe",
        "outputId": "a777e129-247b-4f81-f948-7512f9ab5b50"
      },
      "source": [
        "best_model = clf.export_model()\n",
        "best_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "cast_to_float32 (CastToFloat (None, 28, 28)            0         \n",
            "_________________________________________________________________\n",
            "expand_last_dim (ExpandLastD (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "normalization (Normalization (None, 28, 28, 1)         3         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                92170     \n",
            "_________________________________________________________________\n",
            "classification_head_1 (Softm (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 110,989\n",
            "Trainable params: 110,986\n",
            "Non-trainable params: 3\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwKfWCmQTMTf"
      },
      "source": [
        "\n",
        "### Predict with the best model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPSNnpP6TDAP",
        "outputId": "8a7197d9-02d3-46f0-919a-68b06d1d6f18"
      },
      "source": [
        "predicted_y = clf.predict(x_test)\n",
        "print(predicted_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['7']\n",
            " ['2']\n",
            " ['1']\n",
            " ...\n",
            " ['4']\n",
            " ['5']\n",
            " ['6']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt4cT1OgTMTg",
        "outputId": "47ad8848-9297-49a1-af22-0812e5c6353c"
      },
      "source": [
        "type(predicted_y[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.str_"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywYOH0qYTMTh"
      },
      "source": [
        "### Evaluate the best model on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENEc_5kaTJzn",
        "outputId": "802fd5ac-53b4-4dc0-d66a-d965a0cc9594"
      },
      "source": [
        "\n",
        "test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy: ', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:  0.988099992275238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81QxrNZoTMTi"
      },
      "source": [
        "### Save and load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n84gU_qfTMTj",
        "outputId": "31818420-58a9-4089-a528-34c7cf829d1a"
      },
      "source": [
        "best_model.save(\"model_autokeras\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_autokeras/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dTNi-qBTMTk",
        "outputId": "268197f0-9761-4a95-c3c1-210cb8d72f68"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "loaded_model = load_model(\"model_autokeras\") # , custom_objects=ak.CUSTOM_OBJECTS\n",
        "\n",
        "predicted_y = loaded_model.predict(tf.expand_dims(x_test, -1))\n",
        "print(predicted_y)\n",
        "\n",
        "test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy: ', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.7567700e-10 3.5295128e-11 1.2154676e-08 ... 9.9999976e-01\n",
            "  2.6258207e-10 2.8395709e-08]\n",
            " [6.6249015e-08 6.2428267e-06 9.9999332e-01 ... 1.6883059e-13\n",
            "  1.5260402e-09 1.2889657e-12]\n",
            " [4.9405344e-08 9.9961913e-01 1.8153445e-05 ... 3.0194589e-05\n",
            "  2.4773601e-06 5.2960836e-08]\n",
            " ...\n",
            " [4.9813994e-13 4.9129406e-10 1.7102680e-12 ... 5.6733228e-07\n",
            "  1.4088409e-06 1.0516960e-06]\n",
            " [6.1794730e-10 2.8649080e-12 1.8733258e-10 ... 7.1567530e-11\n",
            "  1.2792475e-05 2.6690681e-09]\n",
            " [4.0928891e-09 8.4695960e-13 4.1557588e-08 ... 4.6263005e-14\n",
            "  1.5417026e-08 1.1706852e-10]]\n",
            "Test accuracy:  0.988099992275238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPg_anuHkux3"
      },
      "source": [
        "## Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BFjZCYilIcK"
      },
      "source": [
        "By default, AutoKeras use the last 20% of training data as validation data. As shown in the example below, you can use validation_split to specify the percentage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEnScrnyiVrk"
      },
      "source": [
        "clf.fit(x_train,\n",
        "        y_train,\n",
        "        # Split the training data and use the last 15% as validation data.\n",
        "        validation_split=0.15,epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_HdBdJqlOwJ"
      },
      "source": [
        "You can also use your own validation set instead of splitting it from the training data with validation_data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31XIV2zVjbxy"
      },
      "source": [
        "split = 50000\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "clf.fit(x_train,\n",
        "        y_train,\n",
        "        # Use your own validation set.\n",
        "        validation_data=(x_val, y_val),epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyT2hCbcl-bh"
      },
      "source": [
        "## Data Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4W38Em6fBqI"
      },
      "source": [
        "The AutoKeras ImageClassifier is quite flexible for the data format.\n",
        "\n",
        "For the image, it accepts data formats both with and without the channel dimension. The images in the MNIST dataset do not have the channel dimension. Each image is a matrix with shape (28, 28). AutoKeras also accepts images of three dimensions with the channel dimension at last, e.g., (32, 32, 3), (28, 28, 1).\n",
        "\n",
        "For the classification labels, AutoKeras accepts both plain labels, i.e. strings or integers, and one-hot encoded encoded labels, i.e. vectors of 0s and 1s.\n",
        "\n",
        "So if you prepare your data in the following way, the ImageClassifier should still work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT_J3DONl76o",
        "outputId": "3517babc-8f4a-4f45-9496-36f72a752aa0"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape the images to have the channel dimension.\n",
        "# x_train = x_train.reshape(x_train.shape + (1,))\n",
        "# x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "\n",
        "# One-hot encode the labels.\n",
        "import numpy as np\n",
        "eye = np.eye(10)\n",
        "y_train = eye[y_train]\n",
        "y_test = eye[y_test]\n",
        "\n",
        "print(x_train.shape) # (60000, 28, 28, 1)\n",
        "print(y_train.shape) # (60000, 10)\n",
        "print(y_train[:3])\n",
        "# array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
        "#        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "#        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPB_oEgtfH6r"
      },
      "source": [
        "We also support using tf.data.Dataset format for the training data. In this case, the images would have to be 3-dimentional. The labels have to be one-hot encoded for multi-class classification to be wrapped into tensorflow Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpFzehXBfLuO"
      },
      "source": [
        "import tensorflow as tf\n",
        "train_set = tf.data.Dataset.from_tensor_slices(((x_train, ), (y_train, )))\n",
        "test_set = tf.data.Dataset.from_tensor_slices(((x_test, ), (y_test, )))\n",
        "\n",
        "clf = ak.ImageClassifier(max_trials=2)\n",
        "# Feed the tensorflow Dataset to the classifier.\n",
        "clf.fit(train_set)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(test_set)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(test_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNcmO1v5TMTt"
      },
      "source": [
        "### Configurate search process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHzEnG7vTMTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4eb265e-a129-4551-dacb-21249332857f"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "clf = ak.ImageClassifier(max_trials=2, \n",
        "                         loss='categorical_crossentropy', \n",
        "                         metrics=['accuracy'],\n",
        "                         objective='val_accuracy',\n",
        "                        )\n",
        "\n",
        "clf.fit(x_train, y_train, \n",
        "        validation_split=0.15,\n",
        "        epochs=3, verbose=2, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 2 Complete [00h 26m 19s]\n",
            "val_accuracy: 0.9221529960632324\n",
            "\n",
            "Best val_accuracy So Far: 0.9883229732513428\n",
            "Total elapsed time: 00h 26m 46s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/3\n",
            "1875/1875 - 5s - loss: 0.1549 - accuracy: 0.9531\n",
            "Epoch 2/3\n",
            "1875/1875 - 5s - loss: 0.0724 - accuracy: 0.9782\n",
            "Epoch 3/3\n",
            "1875/1875 - 5s - loss: 0.0605 - accuracy: 0.9815\n",
            "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Rj6OhhZWgXf"
      },
      "source": [
        "### Customize search objective and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He-byiZYWIx0",
        "outputId": "e0556fb8-9f35-430e-d1b7-49edb3ac591b"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "import kerastuner\n",
        "def my_metric(y_true, y_pred):\n",
        "    correct_labels = tf.cast(y_true == y_pred, tf.float32)\n",
        "    return tf.reduce_mean(correct_labels, axis=-1) \n",
        "\n",
        "clf = ak.ImageClassifier(\n",
        "    seed=42,\n",
        "    max_trials=2,\n",
        "    loss='categorical_crossentropy',\n",
        "    # Wrap the function into a Keras Tuner Objective \n",
        "    # and pass it to AutoKeras.\n",
        "\n",
        "    # Direction can be 'min' or 'max'\n",
        "    # meaning we want to minimize or maximize the metric.\n",
        "\n",
        "    # 'val_my_metric' is just add a 'val_' prefix\n",
        "    # to the function name or the metric name.\n",
        "    objective=kerastuner.Objective('val_my_metric', direction='max'),\n",
        "    # Include it as one of the metrics.\n",
        "    metrics=[my_metric],\n",
        ")\n",
        "\n",
        "clf.fit(x_train, y_train, \n",
        "        validation_split=0.15,\n",
        "        epochs=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 27m 54s]\n",
            "val_my_metric: 0.0009341632248833776\n",
            "\n",
            "Best val_my_metric So Far: 0.0009341632248833776\n",
            "Total elapsed time: 00h 27m 54s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/3\n",
            "Tensor(\"Cast_1:0\", shape=(None, 10), dtype=float32)\n",
            "Tensor(\"Cast_1:0\", shape=(None, 10), dtype=float32)\n",
            "1875/1875 [==============================] - 624s 330ms/step - loss: 0.7643 - my_metric: 2.8465e-05\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 619s 330ms/step - loss: 0.2722 - my_metric: 4.1554e-04\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 618s 329ms/step - loss: 0.2178 - my_metric: 9.2383e-04\n",
            "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBykhsofDoKf"
      },
      "source": [
        "## Reference\n",
        "[ImageClassifier](/image_classifier),\n",
        "[AutoModel](/auto_model/#automodel-class),\n",
        "[ImageBlock](/block/#imageblock-class),\n",
        "[Normalization](/preprocessor/#normalization-class),\n",
        "[ImageAugmentation](/preprocessor/#image-augmentation-class),\n",
        "[ResNetBlock](/block/#resnetblock-class),\n",
        "[ImageInput](/node/#imageinput-class),\n",
        "[ClassificationHead](/head/#classificationhead-class)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_Y8p4gRNFc5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}