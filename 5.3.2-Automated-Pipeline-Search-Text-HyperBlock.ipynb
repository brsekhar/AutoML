{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[-1], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0D7scqBWkg5t"
   },
   "source": [
    "### Load 20newsgroup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YACSvJ81h_Ry"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "categories = ['rec.autos', 'rec.motorcycles']\n",
    "\n",
    "news_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories)\n",
    "news_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, categories=categories)\n",
    "\n",
    "doc_train, label_train = np.array(news_train.data), np.array(news_train.target)\n",
    "doc_test, label_test =  np.array(news_test.data), np.array(news_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels [0 1]. \n",
      "Number of unique labels: 2.\n",
      "\n",
      "\n",
      "The number of documents for training: 1192.\n",
      "The number of documents for testing: 794.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(numpy.str_,\n",
       " 'From: gregl@zimmer.CSUFresno.EDU (Greg Lewis)\\nSubject: Re: WARNING.....(please read)...\\nKeywords: BRICK, TRUCK, DANGER\\nNntp-Posting-Host: zimmer.csufresno.edu\\nOrganization: CSU Fresno\\nLines: 33\\n\\nIn article <1qh336INNfl5@CS.UTK.EDU> larose@austin.cs.utk.edu (Brian LaRose) writes:\\n>This just a warning to EVERYBODY on the net.  Watch out for\\n>folks standing NEXT to the road or on overpasses.   They can\\n>cause SERIOUS HARM to you and your car.  \\n>\\n>(just a cliff-notes version of my story follows)\\n>\\n>10pm last night, I was travelling on the interstate here in\\n>knoxville,  I was taking an offramp exit to another interstate\\n>and my wife suddenly screamed and something LARGE hit the side\\n>of my truck.  We slowed down, but after looking back to see the\\n>vandals standing there, we drove on to the police station.\\n>\\n>She did get a good look at the guy and saw him \"cock his arm\" with\\n>something the size of a cinderblock, BUT I never saw him. We are \\n>VERY lucky the truck sits up high on the road; if it would have hit\\n>her window, it would have killed her. \\n>\\n>The police are looking for the guy, but in all likelyhood he is gone. \\nStuff deleted...\\n\\nI am sorry to report that in Southern California it was a sick sport\\nfor a while to drop concrete blocks from the overpasses onto the\\nfreeway.  Several persons were killed when said blocks came through\\ntheir windshields.  Many overpass bridges are now fenced, and they\\nhave made it illegal to loiter on such bridges (as if that would stop\\nsuch people).  Yet many bridges are NOT fenced.  I always look up at a\\nbridge while I still have time to take evasive action even though this\\n*sport* has not reached us here in Fresno.\\n___________________________________________________________________\\nGreg_Lewis@csufresno.edu\\nPhotojournalism sequence, Department of Journalism\\nCSU Fresno, Fresno, CA 93740\\n')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Unique labels {}. \\nNumber of unique labels: {}.\\n\\n\"\n",
    "      .format(np.unique(label_train), len(np.unique(label_train))))\n",
    "\n",
    "print(\"The number of documents for training: {}.\".format(len(doc_train)))\n",
    "print(\"The number of documents for testing: {}.\".format(len(doc_test)))\n",
    "\n",
    "type(doc_train[0]), doc_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N5xlStkakqJn"
   },
   "source": [
    "### TextToIntSequence Preprocessor Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 30 steps, validate for 8 steps\n",
      "Epoch 1/1000\n",
      "30/30 - 7s - loss: 0.6975 - accuracy: 0.5063 - val_loss: 0.6887 - val_accuracy: 0.4832\n",
      "Epoch 2/1000\n",
      "30/30 - 1s - loss: 0.6825 - accuracy: 0.5639 - val_loss: 0.6698 - val_accuracy: 0.5756\n",
      "Epoch 3/1000\n",
      "30/30 - 2s - loss: 0.5841 - accuracy: 0.8428 - val_loss: 0.4189 - val_accuracy: 0.9412\n",
      "Epoch 4/1000\n",
      "30/30 - 2s - loss: 0.1743 - accuracy: 0.9769 - val_loss: 0.1109 - val_accuracy: 0.9664\n",
      "Epoch 5/1000\n",
      "30/30 - 2s - loss: 0.0193 - accuracy: 0.9958 - val_loss: 0.0692 - val_accuracy: 0.9790\n",
      "Epoch 6/1000\n",
      "30/30 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9790\n",
      "Epoch 7/1000\n",
      "30/30 - 1s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9790\n",
      "Epoch 8/1000\n",
      "30/30 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9748\n",
      "Epoch 9/1000\n",
      "30/30 - 2s - loss: 8.5898e-04 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9790\n",
      "Epoch 10/1000\n",
      "30/30 - 2s - loss: 6.2640e-04 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9790\n",
      "Epoch 11/1000\n",
      "30/30 - 2s - loss: 4.4045e-04 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9748\n",
      "Epoch 12/1000\n",
      "30/30 - 2s - loss: 3.2434e-04 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9748\n",
      "Epoch 13/1000\n",
      "30/30 - 2s - loss: 2.8417e-04 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9790\n",
      "Epoch 14/1000\n",
      "30/30 - 2s - loss: 2.2528e-04 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9748\n",
      "Epoch 15/1000\n",
      "30/30 - 1s - loss: 2.2572e-04 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9790\n",
      "Epoch 16/1000\n",
      "30/30 - 2s - loss: 1.5695e-04 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9790\n",
      "Epoch 17/1000\n",
      "30/30 - 1s - loss: 1.5058e-04 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9748\n",
      "Epoch 18/1000\n",
      "30/30 - 1s - loss: 1.3088e-04 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9748\n",
      "Epoch 19/1000\n",
      "30/30 - 2s - loss: 1.2356e-04 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9748\n",
      "Epoch 20/1000\n",
      "30/30 - 1s - loss: 9.7520e-05 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9748\n",
      "Epoch 21/1000\n",
      "30/30 - 1s - loss: 1.3757e-04 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9748\n",
      "Epoch 22/1000\n",
      "30/30 - 1s - loss: 8.0918e-05 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9790\n",
      "Epoch 23/1000\n",
      "30/30 - 1s - loss: 1.0838e-04 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 4204eabee871339425f0493317732867</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.062146709620719776</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/filters_0_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/kernel_size: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/max_pooling: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/num_blocks: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/separable: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/dense_block_1/units_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/embedding_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/embedding_1/embedding_dim: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/embedding_1/pretraining: none</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/spatial_reduction_1/reduction_type: global_max</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/text_to_int_sequence_1/output_sequence_length: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/vectorizer: sequence</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 30 steps, validate for 8 steps\n",
      "Epoch 1/1000\n",
      "30/30 - 4s - loss: 0.6975 - accuracy: 0.4906 - val_loss: 0.6903 - val_accuracy: 0.4706\n",
      "Epoch 2/1000\n",
      "30/30 - 2s - loss: 0.6832 - accuracy: 0.5891 - val_loss: 0.6682 - val_accuracy: 0.8151\n",
      "Epoch 3/1000\n",
      "30/30 - 2s - loss: 0.5678 - accuracy: 0.8260 - val_loss: 0.3830 - val_accuracy: 0.9412\n",
      "Epoch 4/1000\n",
      "30/30 - 2s - loss: 0.2053 - accuracy: 0.9549 - val_loss: 0.1508 - val_accuracy: 0.9622\n",
      "Epoch 5/1000\n",
      "30/30 - 2s - loss: 0.0436 - accuracy: 0.9895 - val_loss: 0.0744 - val_accuracy: 0.9748\n",
      "Epoch 6/1000\n",
      "30/30 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 0.9832\n",
      "Epoch 7/1000\n",
      "30/30 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9832\n",
      "Epoch 8/1000\n",
      "30/30 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9832\n",
      "Epoch 9/1000\n",
      "30/30 - 1s - loss: 7.9098e-04 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9832\n",
      "Epoch 10/1000\n",
      "30/30 - 2s - loss: 6.4779e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9832\n",
      "Epoch 11/1000\n",
      "30/30 - 1s - loss: 4.6856e-04 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9790\n",
      "Epoch 12/1000\n",
      "30/30 - 1s - loss: 4.0331e-04 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9832\n",
      "Epoch 13/1000\n",
      "30/30 - 2s - loss: 2.8280e-04 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9832\n",
      "Epoch 14/1000\n",
      "30/30 - 1s - loss: 6.3160e-04 - accuracy: 1.0000 - val_loss: 0.0568 - val_accuracy: 0.9790\n",
      "Epoch 15/1000\n",
      "30/30 - 1s - loss: 2.3308e-04 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9748\n",
      "Epoch 16/1000\n",
      "30/30 - 1s - loss: 1.9660e-04 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9832\n",
      "Epoch 17/1000\n",
      "30/30 - 1s - loss: 1.6970e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9832\n",
      "Epoch 18/1000\n",
      "30/30 - 1s - loss: 1.6117e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9832\n",
      "Epoch 19/1000\n",
      "30/30 - 1s - loss: 1.6087e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9832\n",
      "Epoch 20/1000\n",
      "30/30 - 1s - loss: 1.1765e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9832\n",
      "Epoch 21/1000\n",
      "30/30 - 1s - loss: 1.2392e-04 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9832\n",
      "Epoch 22/1000\n",
      "30/30 - 2s - loss: 6.8240e-05 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9874\n",
      "Epoch 23/1000\n",
      "30/30 - 1s - loss: 7.8651e-05 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9832\n",
      "Epoch 24/1000\n",
      "30/30 - 1s - loss: 9.5747e-05 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9832\n",
      "Epoch 25/1000\n",
      "30/30 - 1s - loss: 7.9852e-05 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9832\n",
      "Epoch 26/1000\n",
      "30/30 - 1s - loss: 7.2232e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9832\n",
      "Epoch 27/1000\n",
      "30/30 - 1s - loss: 6.4382e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9832\n",
      "Epoch 28/1000\n",
      "30/30 - 2s - loss: 5.2082e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9832\n",
      "Epoch 29/1000\n",
      "30/30 - 1s - loss: 4.1117e-05 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9832\n",
      "Epoch 30/1000\n",
      "30/30 - 2s - loss: 5.0050e-05 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9832\n",
      "Epoch 31/1000\n",
      "30/30 - 2s - loss: 4.1782e-05 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9832\n",
      "Epoch 32/1000\n",
      "30/30 - 1s - loss: 3.9843e-05 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9832\n",
      "Epoch 33/1000\n",
      "30/30 - 1s - loss: 4.6857e-05 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9832\n",
      "Epoch 34/1000\n",
      "30/30 - 1s - loss: 3.9807e-05 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9832\n",
      "Epoch 35/1000\n",
      "30/30 - 1s - loss: 4.0190e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9832\n",
      "Epoch 36/1000\n",
      "30/30 - 2s - loss: 2.4676e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9832\n",
      "Epoch 37/1000\n",
      "30/30 - 2s - loss: 2.2563e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9832\n",
      "Epoch 38/1000\n",
      "30/30 - 1s - loss: 2.8140e-05 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9832\n",
      "Epoch 39/1000\n",
      "30/30 - 2s - loss: 2.4594e-05 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9832\n",
      "Epoch 40/1000\n",
      "30/30 - 1s - loss: 2.0600e-05 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9832\n",
      "Epoch 41/1000\n",
      "30/30 - 2s - loss: 2.2697e-05 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9832\n",
      "Epoch 42/1000\n",
      "30/30 - 2s - loss: 3.0172e-05 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: b98ef2e890bebcaad2f5cdffa13045b2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.041898843468516134</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/filters_0_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/kernel_size: 5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/max_pooling: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/num_blocks: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/conv_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/conv_block_1/separable: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/dense_block_1/dropout_rate: 0.5</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/dense_block_1/num_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/dense_block_1/units_0: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/dense_block_1/use_batchnorm: False</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/embedding_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/embedding_1/embedding_dim: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/embedding_1/pretraining: none</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/spatial_reduction_1/reduction_type: global_max</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-text_block_1/text_to_int_sequence_1/output_sequence_length: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-text_block_1/vectorizer: sequence</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Train for 38 steps, validate for 8 steps\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[20,105] = 20000 is not in [0, 20000)\n\t [[node model/embedding/embedding_lookup (defined at /home/qq/.virtualenvs/book/lib/python3.6/site-packages/autokeras/engine/tuner.py:135) ]]\n\t [[VariableShape/_50]]\n  (1) Invalid argument:  indices[20,105] = 20000 is not in [0, 20000)\n\t [[node model/embedding/embedding_lookup (defined at /home/qq/.virtualenvs/book/lib/python3.6/site-packages/autokeras/engine/tuner.py:135) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_72215]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/embedding/embedding_lookup:\n model/embedding/embedding_lookup/71842 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nInput Source operations connected to node model/embedding/embedding_lookup:\n model/embedding/embedding_lookup/71842 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5802ebba4019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Feed the text classifier with training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/autokeras/tasks/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m                           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                           \u001b[0mfit_on_val_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                           **kwargs)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, callbacks, fit_on_val_data, **fit_kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m                     fit_kwargs['validation_data'])\n\u001b[1;32m    122\u001b[0m                 \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'callbacks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deepcopy_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36mfinal_fit\u001b[0;34m(self, x, **fit_kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/.virtualenvs/book/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[20,105] = 20000 is not in [0, 20000)\n\t [[node model/embedding/embedding_lookup (defined at /home/qq/.virtualenvs/book/lib/python3.6/site-packages/autokeras/engine/tuner.py:135) ]]\n\t [[VariableShape/_50]]\n  (1) Invalid argument:  indices[20,105] = 20000 is not in [0, 20000)\n\t [[node model/embedding/embedding_lookup (defined at /home/qq/.virtualenvs/book/lib/python3.6/site-packages/autokeras/engine/tuner.py:135) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_72215]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/embedding/embedding_lookup:\n model/embedding/embedding_lookup/71842 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nInput Source operations connected to node model/embedding/embedding_lookup:\n model/embedding/embedding_lookup/71842 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "input_node = ak.TextInput()\n",
    "output_node = ak.TextToIntSequence(max_tokens=500)(input_node)\n",
    "output_node = ak.Embedding(embedding_dim=100)(output_node)\n",
    "output_node = ak.RNNBlock()(output_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "auto_model = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)\n",
    "\n",
    "auto_model.fit(x_train, y_train,epochs=3, verbose=2)\n",
    "test_loss, test_acc = auto_model.evaluate(doc_test, label_test, verbose=0)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextToNgramVector Preprocessor Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import autokeras as ak\n",
    "\n",
    "input_node = ak.TextInput()\n",
    "output_node = ak.TextToNgramVector(max_tokens=500)(input_node)\n",
    "output_node = ak.DenseBlock()(output_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "auto_model = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)\n",
    "\n",
    "test_loss, test_acc = auto_model.evaluate(doc_test, label_test, verbose=0)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBykhsofDoKf"
   },
   "source": [
    "## Reference\n",
    "[ImageClassifier](/image_classifier),\n",
    "[AutoModel](/auto_model/#automodel-class),\n",
    "[ImageBlock](/block/#imageblock-class),\n",
    "[Normalization](/preprocessor/#normalization-class),\n",
    "[ImageAugmentation](/preprocessor/#image-augmentation-class),\n",
    "[ResNetBlock](/block/#resnetblock-class),\n",
    "[ImageInput](/node/#imageinput-class),\n",
    "[ClassificationHead](/head/#classificationhead-class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ImageClassifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
