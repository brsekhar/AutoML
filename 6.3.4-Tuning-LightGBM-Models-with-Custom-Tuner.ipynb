{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.3.4-Tuning-LightGBM-Models-with-Custom-Tuner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdAGu8W7jdAM",
        "outputId": "e00b9d01-0569-4b08-dcc9-21051e1499fc"
      },
      "source": [
        "!pip install keras-tuner -q\n",
        "!pip install lightgbm -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 22.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.7MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq-4QQMmq3YL"
      },
      "source": [
        "### Load the California housing price prediction dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S65cPxQjj8j_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e72012ac-fa7b-4248-c9db-07a5598054a6"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "house_dataset = fetch_california_housing()\n",
        "\n",
        "# Import pandas package to format the data\n",
        "import pandas as pd\n",
        "\n",
        "# Extract features with their names into the a dataframe format\n",
        "data = pd.DataFrame(house_dataset.data, columns=house_dataset.feature_names)\n",
        "\n",
        "# Extract target with their names into a pd.Series object with name MEDV\n",
        "target = pd.Series(house_dataset.target, name = 'MEDV')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y0W-z1KJCiR"
      },
      "source": [
        "### Use LightGBM GBDT model to do regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87aDsubsJBq0",
        "outputId": "54ac4e94-5c86-450f-82be-981c15e7f97e"
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "gbdt_model = lgb.LGBMRegressor(\n",
        "                    boosting_type='gbdt',\n",
        "                    num_leaves=31,\n",
        "                    learning_rate=0.05,\n",
        "                    n_estimators=10\n",
        "                    )  # create model\n",
        "\n",
        "validation_data = (X_val, y_val)\n",
        "gbdt_model.fit(X_train, y_train,\n",
        "        eval_set=[validation_data],\n",
        "        eval_metric='mse',\n",
        "        early_stopping_rounds=5) # fit the model\n",
        "\n",
        "# evalaute model\n",
        "y_pred_gbdt = gbdt_model.predict(X_test, num_iteration=gbdt_model.best_iteration_)\n",
        "test_mse_1 = mean_squared_error(y_test, y_pred_gbdt)\n",
        "print(\"The GBDT prediction MSE on test set: {}\".format(test_mse_1))\n",
        "\n",
        "# save, load, and evaluate the model\n",
        "fname = 'gbdt_model.txt'\n",
        "gbdt_model.booster_.save_model(fname, num_iteration=gbdt_model.best_iteration_) \n",
        "\n",
        "gbdt_model_2 = lgb.Booster(model_file=fname)\n",
        "gbdt_model_2.predict(X_test)\n",
        "test_mse_2 = mean_squared_error(y_test, y_pred_gbdt)\n",
        "print(\"The reloaded GBDT prediction MSE on test set: {}\".format(test_mse_2))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's l2: 1.28051\tvalid_0's l2: 1.28051\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's l2: 1.2009\tvalid_0's l2: 1.2009\n",
            "[3]\tvalid_0's l2: 1.1316\tvalid_0's l2: 1.1316\n",
            "[4]\tvalid_0's l2: 1.06506\tvalid_0's l2: 1.06506\n",
            "[5]\tvalid_0's l2: 1.00734\tvalid_0's l2: 1.00734\n",
            "[6]\tvalid_0's l2: 0.952642\tvalid_0's l2: 0.952642\n",
            "[7]\tvalid_0's l2: 0.903993\tvalid_0's l2: 0.903993\n",
            "[8]\tvalid_0's l2: 0.857114\tvalid_0's l2: 0.857114\n",
            "[9]\tvalid_0's l2: 0.815805\tvalid_0's l2: 0.815805\n",
            "[10]\tvalid_0's l2: 0.778275\tvalid_0's l2: 0.778275\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[10]\tvalid_0's l2: 0.778275\tvalid_0's l2: 0.778275\n",
            "The GBDT prediction MSE on test set: 0.7514642734431766\n",
            "The reloaded GBDT prediction MSE on test set: 0.7514642734431766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X1qjTA2G0H4"
      },
      "source": [
        "### Create the LightGBM model building function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRophLeFkIF1"
      },
      "source": [
        "def build_model(hp):\n",
        "    model = lgb.LGBMRegressor(\n",
        "                        boosting_type='gbdt',\n",
        "                        num_leaves=hp.Choice(\"num_leaves\", [15, 31, 63], default=31),\n",
        "                        learning_rate=hp.Float('learning_rate', 1e-3, 10, sampling='log', default=0.05),\n",
        "                        n_estimators=hp.Int('n_estimators', 10, 200, step=10)\n",
        "                        )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ivw9IzYG5c9"
      },
      "source": [
        "### Customize the LightGBM tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjfR1T8MpAs9"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import kerastuner as kt\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "class LightGBMTuner(kt.engine.base_tuner.BaseTuner):\n",
        "\n",
        "    def run_trial(self, trial, X, y, validation_data):\n",
        "        model = self.hypermodel.build(trial.hyperparameters) # build the model\n",
        "        model.fit(X_train, y_train,\n",
        "                eval_set=[validation_data],\n",
        "                eval_metric='mse',\n",
        "                early_stopping_rounds=5) # fit the model\n",
        "        X_val, y_val = validation_data\n",
        "        y_pred = model.predict(X_val, num_iteration=model.best_iteration_) # evaluate the model\n",
        "        eval_mse = mean_squared_error(y_val, y_pred)\n",
        "        self.oracle.update_trial(trial.trial_id, {'mse': eval_mse})  # inform the oracle of the eval result, the result is a dictionary with the metric names as the keys.\n",
        "        self.save_model(trial.trial_id, model) # save the model to disk\n",
        "\n",
        "    def save_model(self, trial_id, model, step=0):\n",
        "        fname = os.path.join(self.get_trial_dir(trial_id), 'model.txt')\n",
        "        model.booster_.save_model(fname, num_iteration=model.best_iteration_) \n",
        "\n",
        "    def load_model(self, trial):\n",
        "        fname = os.path.join(self.get_trial_dir(trial.trial_id), 'model.txt')\n",
        "        model = lgb.Booster(model_file=fname)\n",
        "        return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beZNzbC4G_Zj"
      },
      "source": [
        "### Run the tuner to select a LightGBM models for the housing price prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esZnzMinpDYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d17aac-7c49-413d-ef7a-5dd6be9c2dbf"
      },
      "source": [
        "my_lightgbm_tuner = LightGBMTuner(\n",
        "        oracle=kt.oracles.RandomSearch(\n",
        "            objective=kt.Objective('mse', 'min'),\n",
        "            max_trials=10,\n",
        "            seed=42),\n",
        "        hypermodel=build_model,\n",
        "        overwrite=True,\n",
        "        project_name='my_lightgbm_tuner')\n",
        "\n",
        "my_lightgbm_tuner.search(X_train, y_train, validation_data=(X_val, y_val))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 00m 00s]\n",
            "mse: 11.151438308866505\n",
            "\n",
            "Best mse So Far: 0.2202899505068673\n",
            "Total elapsed time: 00h 00m 03s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_EFBFB6G-of"
      },
      "source": [
        "### Evaluate the best discovered model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g7XTqRjkQun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e2b833-d4e7-446c-e130-64e8b8d5467b"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "best_model = my_lightgbm_tuner.get_best_models(1)[0]\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "test_mse = mean_squared_error(y_test, y_pred_test)\n",
        "print(\"The prediction MSE on test set: {}\".format(test_mse))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction MSE on test set: 0.20391543433512713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c0y454tHUSB"
      },
      "source": [
        "### Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7JlBIXAL-ZU",
        "outputId": "c192c733-9c12-4d90-9351-5ca79252dd43"
      },
      "source": [
        "my_lightgbm_tuner.get_best_models(1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<lightgbm.basic.Booster at 0x7f6c2f1fc190>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPzWce8gEBYT",
        "outputId": "73a68b8a-93d1-450c-f6c0-6a39ec65b107"
      },
      "source": [
        "my_lightgbm_tuner.results_summary(1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./my_lightgbm_tuner\n",
            "Showing 1 best trials\n",
            "Objective(name='mse', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_leaves: 31\n",
            "learning_rate: 0.09504947970741313\n",
            "n_estimators: 190\n",
            "Score: 0.2202899505068673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJyuSZf-e6YB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}