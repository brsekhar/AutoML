{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 6.3.4-Tuning-LightGBM-Models-with-Custom-Tuner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdAGu8W7jdAM",
        "outputId": "041e86f9-9307-4f91-e772-314807ad9443"
      },
      "source": [
        "!pip install keras-tuner -q\n",
        "!pip install lightgbm -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 92 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 97 kB 2.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq-4QQMmq3YL"
      },
      "source": [
        "### Load the California housing price prediction dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S65cPxQjj8j_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6e13ea-c91e-4d56-9a1e-8b5d6d1902e3"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "house_dataset = fetch_california_housing()\n",
        "\n",
        "# Import pandas package to format the data\n",
        "import pandas as pd\n",
        "\n",
        "# Extract features with their names into the a dataframe format\n",
        "data = pd.DataFrame(house_dataset.data, columns=house_dataset.feature_names)\n",
        "\n",
        "# Extract target with their names into a pd.Series object with name MEDV\n",
        "target = pd.Series(house_dataset.target, name = 'MEDV')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y0W-z1KJCiR"
      },
      "source": [
        "### Use LightGBM GBDT model to do regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87aDsubsJBq0",
        "outputId": "9c854898-949c-443f-c48c-e6ff8e7c95e6"
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "gbdt_model = lgb.LGBMRegressor(\n",
        "                    boosting_type='gbdt',\n",
        "                    num_leaves=31,\n",
        "                    learning_rate=0.05,\n",
        "                    n_estimators=10\n",
        "                    )  # create model\n",
        "\n",
        "validation_data = (X_val, y_val)\n",
        "gbdt_model.fit(X_train, y_train,\n",
        "        eval_set=[validation_data],\n",
        "        eval_metric='mse',\n",
        "        early_stopping_rounds=5) # fit the model\n",
        "\n",
        "# evalaute model\n",
        "y_pred_gbdt = gbdt_model.predict(X_test, num_iteration=gbdt_model.best_iteration_)\n",
        "test_mse_1 = mean_squared_error(y_test, y_pred_gbdt)\n",
        "print(\"The GBDT prediction MSE on test set: {}\".format(test_mse_1))\n",
        "\n",
        "# save, load, and evaluate the model\n",
        "fname = 'gbdt_model.txt'\n",
        "gbdt_model.booster_.save_model(fname, num_iteration=gbdt_model.best_iteration_) \n",
        "\n",
        "gbdt_model_2 = lgb.Booster(model_file=fname)\n",
        "gbdt_model_2.predict(X_test)\n",
        "test_mse_2 = mean_squared_error(y_test, y_pred_gbdt)\n",
        "print(\"The reloaded GBDT prediction MSE on test set: {}\".format(test_mse_2))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's l2: 1.28051\tvalid_0's l2: 1.28051\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's l2: 1.2009\tvalid_0's l2: 1.2009\n",
            "[3]\tvalid_0's l2: 1.1316\tvalid_0's l2: 1.1316\n",
            "[4]\tvalid_0's l2: 1.06506\tvalid_0's l2: 1.06506\n",
            "[5]\tvalid_0's l2: 1.00734\tvalid_0's l2: 1.00734\n",
            "[6]\tvalid_0's l2: 0.952642\tvalid_0's l2: 0.952642\n",
            "[7]\tvalid_0's l2: 0.903993\tvalid_0's l2: 0.903993\n",
            "[8]\tvalid_0's l2: 0.857114\tvalid_0's l2: 0.857114\n",
            "[9]\tvalid_0's l2: 0.815805\tvalid_0's l2: 0.815805\n",
            "[10]\tvalid_0's l2: 0.778275\tvalid_0's l2: 0.778275\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[10]\tvalid_0's l2: 0.778275\tvalid_0's l2: 0.778275\n",
            "The GBDT prediction MSE on test set: 0.7514642734431766\n",
            "The reloaded GBDT prediction MSE on test set: 0.7514642734431766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X1qjTA2G0H4"
      },
      "source": [
        "### Create the LightGBM model building function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRophLeFkIF1"
      },
      "source": [
        "def build_model(hp):\n",
        "    model = lgb.LGBMRegressor(\n",
        "                        boosting_type='gbdt',\n",
        "                        num_leaves=hp.Choice(\"num_leaves\", [15, 31, 63], default=31),\n",
        "                        learning_rate=hp.Float('learning_rate', 1e-3, 10, sampling='log', default=0.05),\n",
        "                        n_estimators=hp.Int('n_estimators', 10, 200, step=10)\n",
        "                        )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ivw9IzYG5c9"
      },
      "source": [
        "### Customize the LightGBM tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjfR1T8MpAs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5f987f-b720-4402-f2b7-07700b9ef04b"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import kerastuner as kt\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "class LightGBMTuner(kt.engine.base_tuner.BaseTuner):\n",
        "\n",
        "    def run_trial(self, trial, X, y, validation_data):\n",
        "        model = self.hypermodel.build(trial.hyperparameters) # build the model\n",
        "        model.fit(X_train, y_train,\n",
        "                eval_set=[validation_data],\n",
        "                eval_metric='mse',\n",
        "                early_stopping_rounds=5) # fit the model\n",
        "        X_val, y_val = validation_data\n",
        "        y_pred = model.predict(X_val, num_iteration=model.best_iteration_) # evaluate the model\n",
        "        eval_mse = mean_squared_error(y_val, y_pred)\n",
        "        self.oracle.update_trial(trial.trial_id, {'mse': eval_mse})  # inform the oracle of the eval result, the result is a dictionary with the metric names as the keys.\n",
        "        self.save_model(trial.trial_id, model) # save the model to disk\n",
        "\n",
        "    def save_model(self, trial_id, model, step=0):\n",
        "        fname = os.path.join(self.get_trial_dir(trial_id), 'model.txt')\n",
        "        model.booster_.save_model(fname, num_iteration=model.best_iteration_) \n",
        "\n",
        "    def load_model(self, trial):\n",
        "        fname = os.path.join(self.get_trial_dir(trial.trial_id), 'model.txt')\n",
        "        model = lgb.Booster(model_file=fname)\n",
        "        return model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beZNzbC4G_Zj"
      },
      "source": [
        "### Run the tuner to select a LightGBM models for the housing price prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esZnzMinpDYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05596bb-dc8b-4514-f3c1-edf6f6af3e6a"
      },
      "source": [
        "my_lightgbm_tuner = LightGBMTuner(\n",
        "        oracle=kt.oracles.RandomSearch(\n",
        "            objective=kt.Objective('mse', 'min'),\n",
        "            max_trials=10,\n",
        "            seed=42),\n",
        "        hypermodel=build_model,\n",
        "        overwrite=True,\n",
        "        project_name='my_lightgbm_tuner')\n",
        "\n",
        "my_lightgbm_tuner.search(X_train, y_train, validation_data=(X_val, y_val))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 00s]\n",
            "mse: 11.151438308866505\n",
            "\n",
            "Best mse So Far: 0.2202899505068673\n",
            "Total elapsed time: 00h 00m 14s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_EFBFB6G-of"
      },
      "source": [
        "### Evaluate the best discovered model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g7XTqRjkQun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b34013f-7bd0-43f1-9d34-8c8e81800ff7"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "best_model = my_lightgbm_tuner.get_best_models(1)[0]\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "test_mse = mean_squared_error(y_test, y_pred_test)\n",
        "print(\"The prediction MSE on test set: {}\".format(test_mse))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction MSE on test set: 0.20391543433512713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c0y454tHUSB"
      },
      "source": [
        "### Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7JlBIXAL-ZU",
        "outputId": "00f1a861-20f1-419b-a05d-a5e705077a9c"
      },
      "source": [
        "my_lightgbm_tuner.get_best_models(1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<lightgbm.basic.Booster at 0x7efe9db5a5d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPzWce8gEBYT",
        "outputId": "9cf19ceb-a5aa-43ae-a131-d4f62437d2a0"
      },
      "source": [
        "my_lightgbm_tuner.results_summary(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./my_lightgbm_tuner\n",
            "Showing 1 best trials\n",
            "Objective(name='mse', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_leaves: 31\n",
            "learning_rate: 0.09504947970741313\n",
            "n_estimators: 190\n",
            "Score: 0.2202899505068673\n"
          ]
        }
      ]
    }
  ]
}