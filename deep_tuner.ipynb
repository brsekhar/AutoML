{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_tuner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCv-NB5A7t97",
        "outputId": "c04ad61e-899c-4785-e352-15253fa53b40"
      },
      "source": [
        "!pip install keras-tuner -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.1MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNBm5ZIVAmVF"
      },
      "source": [
        "import copy\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from kerastuner.engine import base_tuner\n",
        "\n",
        "class DeepTuner(base_tuner.BaseTuner):\n",
        "\n",
        "    def run_trial(self, trial, x, y, validation_data, **fit_kwargs):\n",
        "        model = self.hypermodel.build(trial.hyperparameters)\n",
        "        model.fit(x, y, validation_data=validation_data,\n",
        "                  batch_size=trial.hyperparameters.Choice(\"batch_size\", [16, 32]),\n",
        "                  **fit_kwargs)\n",
        "\n",
        "        x_val, y_val = validation_data  # get the validation data\n",
        "        self.oracle.update_trial(trial.trial_id,\n",
        "                                 {name: value for name, value in zip(\n",
        "                                     model.metrics_names, \n",
        "                                     model.evaluate(x_val, y_val))})  # inform the oracle of the eval result, the result is a dictionary with the metric names as the keys.\n",
        "        self.save_model(trial.trial_id, model) # save the model to disk\n",
        "\n",
        "    def save_model(self, trial_id, model):\n",
        "        fname = os.path.join(self.get_trial_dir(trial_id), 'model.pickle')\n",
        "        model.save(fname)\n",
        "\n",
        "    def load_model(self, trial):\n",
        "        fname = os.path.join(self.get_trial_dir(trial.trial_id), 'model.pickle')\n",
        "        model = tf.keras.models.load_model(fname)\n",
        "        return model\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOxBj6biAGHl"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# Load the hand-written digits dataset\n",
        "digits = load_digits()\n",
        "\n",
        "# Get the images and corresponding labels\n",
        "images, labels = digits.images, digits.target\n",
        "images.shape, labels.shape\n",
        "\n",
        "# reshape images to vectors\n",
        "n_samples = len(digits.images)\n",
        "X = digits.images.reshape((n_samples, -1))\n",
        "\n",
        "# Split data into train and test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, labels, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, shuffle=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pme7Cn8iDdVO",
        "outputId": "9b10817e-fbbc-4f0e-b2b1-d50f296a134b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZNVjmEyDkyS",
        "outputId": "364bc7c5-b455-49a7-b3e5-10fc9d0639ef"
      },
      "source": [
        "import kerastuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.Input(shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            tf.keras.layers.Conv2D(hp.Choice(\"filters\", [64, 128, 256]), kernel_size=(3, 3), activation=\"relu\"),\n",
        "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "        ])\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "random_tuner = DeepTuner(\n",
        "        oracle=kt.oracles.RandomSearch(\n",
        "            objective=kt.Objective('accuracy', 'max'),\n",
        "            max_trials=3,\n",
        "            seed=42),\n",
        "        hypermodel=build_model,\n",
        "        overwrite=True,\n",
        "        project_name='random_tuner')\n",
        "\n",
        "random_tuner.search(x_train[:10], y_train[:10], validation_data=(x_test, y_test))\n",
        "random_tuner.search_space_summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 00m 09s]\n",
            "accuracy: 0.1615000069141388\n",
            "\n",
            "Best accuracy So Far: 0.20149999856948853\n",
            "Total elapsed time: 00h 00m 29s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Search space summary\n",
            "Default search space size: 2\n",
            "filters (Choice)\n",
            "{'default': 64, 'conditions': [], 'values': [64, 128, 256], 'ordered': True}\n",
            "batch_size (Choice)\n",
            "{'default': 16, 'conditions': [], 'values': [16, 32], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3R4udwvFbrM",
        "outputId": "748b3c1b-4201-4c41-c912-6a517077d611"
      },
      "source": [
        "best_model = random_tuner.get_best_models(1)[0]\n",
        "y_pred_test = best_model.evaluate(x_test, y_test)\n",
        "print(y_pred_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 2.2968 - accuracy: 0.2015\n",
            "[2.2968461513519287, 0.20149999856948853]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}